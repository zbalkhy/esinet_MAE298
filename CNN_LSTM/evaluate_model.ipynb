{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bd4c0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 15:07:20.575761: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-25 15:07:20.632729: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-25 15:07:21.593619: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from convnet import ConvDipNet\n",
    "from timeDistributed import TimeDistributed\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys; sys.path.insert(0, '../')\n",
    "from esinet.forward import create_forward_model, get_info\n",
    "from esinet import Simulation\n",
    "from copy import deepcopy\n",
    "from CNN_LSTM.util import *\n",
    "from dipoleDataset import DipoleDataset\n",
    "import os\n",
    "import mne\n",
    "from esinet.evaluate import eval_auc, eval_nmse, eval_mse, eval_mean_localization_error\n",
    "\n",
    "from util import solve_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88c69403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ConvDipNet                               [32, 5124]                --\n",
       "├─Conv2d: 1-1                            [32, 8, 9, 9]             80\n",
       "├─BatchNorm2d: 1-2                       [32, 8, 9, 9]             16\n",
       "├─Linear: 1-3                            [32, 512]                 332,288\n",
       "├─BatchNorm1d: 1-4                       [32, 512]                 1,024\n",
       "├─Linear: 1-5                            [32, 5124]                2,628,612\n",
       "==========================================================================================\n",
       "Total params: 2,962,020\n",
       "Trainable params: 2,962,020\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 94.99\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 1.91\n",
       "Params size (MB): 11.85\n",
       "Estimated Total Size (MB): 13.76\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define hyperparameters\n",
    "in_channels = 1\n",
    "im_shape = (9,9)\n",
    "n_filters = 8\n",
    "kernel_size = (3,3)\n",
    "\n",
    "# create single input ConvDipNet \n",
    "convnet: nn.Module  = ConvDipNet(in_channels, im_shape, n_filters, kernel_size)\n",
    "\n",
    "\n",
    "# print model summary\n",
    "summary(convnet, input_size=(32, 1, im_shape[0], im_shape[1])) # (batch_size, n_timesteps, in_channels, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a55af6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvDipNet(\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (hidden_layer): Linear(in_features=648, out_features=512, bias=True)\n",
       "  (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (output_layer): Linear(in_features=512, out_features=5124, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weight_path = \"/mnt/data/convdip/model/convdip_499.pt\"\n",
    "convnet.load_state_dict(torch.load(model_weight_path, weights_only=True))\n",
    "convnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "728aa07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = \"/mnt/data/convdip/model/\"\n",
    "loss_save_path = \"/mnt/data/convdip/model/convdip_loss.npy\"\n",
    "data_path = \"/mnt/data/convdip/training_data/\"\n",
    "eeg_data_path = os.path.join(data_path, \"eeg_data\")\n",
    "interp_data_path = os.path.join(data_path, \"interp_data\")\n",
    "source_data_path = os.path.join(data_path, \"source_data\")\n",
    "info_path = os.path.join(data_path, \"info.fif\")\n",
    "\n",
    "dataset = DipoleDataset(eeg_data_path, interp_data_path, source_data_path, info_path, im_shape=im_shape)\n",
    "test_size = 0.15\n",
    "val_size = 0.15\n",
    "\n",
    "test_amount, val_amount = int(dataset.__len__() * test_size), int(dataset.__len__() * val_size)\n",
    "\n",
    "# this function will automatically randomly split your dataset but you could also implement the split yourself\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(0) # this is the seed we use to split the data the same way each time\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [\n",
    "            (dataset.__len__() - (test_amount + val_amount)), \n",
    "            test_amount, \n",
    "            val_amount\n",
    "], generator=gen)\n",
    "\n",
    "B = 512  # batch size\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "            train_set,\n",
    "            batch_size=B,\n",
    "            shuffle=False,\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "            val_set,\n",
    "            batch_size=B,\n",
    "            shuffle=False,\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "            test_set,\n",
    "            batch_size=B,\n",
    "            shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e268634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24175\n"
     ]
    }
   ],
   "source": [
    "dipole_pos = np.load(os.path.join(data_path, \"dipole_pos.npy\"))\n",
    "\n",
    "idx, sample, target = val_dataloader.dataset[0]\n",
    "print(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0330d0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  80 | elapsed:    5.4s remaining:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  80 | elapsed:    5.5s remaining:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  80 | elapsed:    5.6s remaining:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of  80 | elapsed:    5.6s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    5.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  80 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  80 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  80 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of  80 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  80 | elapsed:    1.5s remaining:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  80 | elapsed:    1.7s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  80 | elapsed:    2.0s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of  80 | elapsed:    2.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    2.4s finished\n"
     ]
    }
   ],
   "source": [
    "# create forward model\n",
    "fs = 100\n",
    "info = get_info(sfreq=fs)\n",
    "fwd = create_forward_model(sampling='ico4', info=info)\n",
    "leadfield = fwd['sol']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "241a83e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample:   3%|▎         | 15/512 [08:09<4:30:17, 32.63s/it]\n",
      "batch:   0%|          | 0/30 [08:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m auc_close, auc_far \u001b[38;5;241m=\u001b[39m eval_auc(target_sample, output_sample, dipole_pos)\n\u001b[1;32m     22\u001b[0m sample_auc \u001b[38;5;241m=\u001b[39m (auc_close \u001b[38;5;241m+\u001b[39m auc_far)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 24\u001b[0m mle \u001b[38;5;241m=\u001b[39m \u001b[43meval_mean_localization_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdipole_pos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m mse \u001b[38;5;241m=\u001b[39m eval_mse(target_sample, output_sample)\n\u001b[1;32m     26\u001b[0m nmse \u001b[38;5;241m=\u001b[39m eval_nmse(target_sample, output_sample)\n",
      "File \u001b[0;32m~/convdip/esinet_MAE298/CNN_LSTM/../esinet/evaluate/evaluate.py:126\u001b[0m, in \u001b[0;36meval_mean_localization_error\u001b[0;34m(y_true, y_est, pos, k_neighbors, min_dist, threshold, ghost_thresh, argsorted_distance_matrix)\u001b[0m\n\u001b[1;32m    121\u001b[0m y_true \u001b[38;5;241m=\u001b[39m deepcopy(y_true)\n\u001b[1;32m    122\u001b[0m y_est \u001b[38;5;241m=\u001b[39m deepcopy(y_est)\n\u001b[1;32m    125\u001b[0m maxima_true \u001b[38;5;241m=\u001b[39m get_maxima_pos(\n\u001b[0;32m--> 126\u001b[0m     \u001b[43mget_maxima_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43margsorted_distance_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margsorted_distance_matrix\u001b[49m\u001b[43m)\u001b[49m, pos)\n\u001b[1;32m    129\u001b[0m maxima_est \u001b[38;5;241m=\u001b[39m get_maxima_pos(\n\u001b[1;32m    130\u001b[0m     get_maxima_mask(y_est, pos, k_neighbors\u001b[38;5;241m=\u001b[39mk_neighbors,\n\u001b[1;32m    131\u001b[0m     threshold\u001b[38;5;241m=\u001b[39mthreshold, min_dist\u001b[38;5;241m=\u001b[39mmin_dist, \n\u001b[1;32m    132\u001b[0m     argsorted_distance_matrix\u001b[38;5;241m=\u001b[39margsorted_distance_matrix), pos)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Distance matrix between every true and estimated maximum\u001b[39;00m\n",
      "File \u001b[0;32m~/convdip/esinet_MAE298/CNN_LSTM/../esinet/evaluate/evaluate.py:27\u001b[0m, in \u001b[0;36mget_maxima_mask\u001b[0;34m(y, pos, k_neighbors, threshold, min_dist, argsorted_distance_matrix)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m''' Returns the mask containing the source maxima (binary).\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    be of significance. 0.1 -> 10% of the absolute maximum\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m argsorted_distance_matrix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m     argsorted_distance_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[43mcdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     30\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(y)\n\u001b[1;32m     31\u001b[0m threshold \u001b[38;5;241m=\u001b[39m threshold\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mmax(y)\n",
      "File \u001b[0;32m~/.pyenv/versions/esienv/lib/python3.12/site-packages/scipy/spatial/distance.py:2980\u001b[0m, in \u001b[0;36mcdist\u001b[0;34m(XA, XB, metric, out, **kwargs)\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2979\u001b[0m     cdist_fn \u001b[38;5;241m=\u001b[39m metric_info\u001b[38;5;241m.\u001b[39mcdist_func\n\u001b[0;32m-> 2980\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcdist_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mstr\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   2982\u001b[0m     metric_info \u001b[38;5;241m=\u001b[39m _TEST_METRICS\u001b[38;5;241m.\u001b[39mget(mstr, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "convnet.to(device)\n",
    "with torch.no_grad():\n",
    "    metrics_per_sample = {}\n",
    "    for idxs, batch, target in tqdm(val_dataloader, position=0, desc=\"batch\"):\n",
    "        batch = batch.to(device, dtype=torch.float)\n",
    "        output = convnet(batch)\n",
    "        output = output.cpu()\n",
    "\n",
    "        for idx in tqdm(range(output.shape[0]), position=1, desc=\"sample\"):\n",
    "            data_idx = int(idxs[idx])\n",
    "            target_sample = np.array(target[idx])\n",
    "            output_sample = np.array(output[idx])\n",
    "            \n",
    "            eeg = np.load(os.path.join(data_path, f\"eeg_data/sample_{data_idx}.npy\"))\n",
    "            max_idx = np.unravel_index(np.argmax(eeg), eeg.shape)[1] # this is the timestep with the maximum eeg value, this will be used to train\n",
    "            output_sample = solve_p(output_sample, eeg[:,max_idx], leadfield)\n",
    "\n",
    "            \n",
    "            auc_close, auc_far = eval_auc(target_sample, output_sample, dipole_pos)\n",
    "            sample_auc = (auc_close + auc_far)/2\n",
    "            \n",
    "            mle = eval_mean_localization_error(target_sample, output_sample, dipole_pos)\n",
    "            mse = eval_mse(target_sample, output_sample)\n",
    "            nmse = eval_nmse(target_sample, output_sample)\n",
    "            metrics_per_sample[data_idx] = [sample_auc, mle, mse, nmse]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
