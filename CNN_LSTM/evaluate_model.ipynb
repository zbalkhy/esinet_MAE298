{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bd4c0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 21:55:35.912600: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-29 21:55:35.967707: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-29 21:55:36.914888: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from convnet import ConvDipNet\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys; sys.path.insert(0, '../')\n",
    "from esinet.forward import create_forward_model, get_info\n",
    "from CNN_LSTM.util import *\n",
    "from dipoleDataset import DipoleDataset\n",
    "import os\n",
    "from esinet.evaluate import eval_auc, eval_nmse, eval_mse, eval_mean_localization_error\n",
    "import json\n",
    "from util import solve_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88c69403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ConvDipNet                               [32, 5124]                --\n",
       "├─Conv2d: 1-1                            [32, 8, 9, 9]             80\n",
       "├─BatchNorm2d: 1-2                       [32, 8, 9, 9]             16\n",
       "├─Conv2d: 1-3                            [32, 8, 9, 9]             584\n",
       "├─BatchNorm2d: 1-4                       [32, 8, 9, 9]             16\n",
       "├─Dropout: 1-5                           [32, 8, 9, 9]             --\n",
       "├─Linear: 1-6                            [32, 512]                 332,288\n",
       "├─BatchNorm1d: 1-7                       [32, 512]                 1,024\n",
       "├─Linear: 1-8                            [32, 5124]                2,628,612\n",
       "==========================================================================================\n",
       "Total params: 2,962,620\n",
       "Trainable params: 2,962,620\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 96.50\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 2.24\n",
       "Params size (MB): 11.85\n",
       "Estimated Total Size (MB): 14.10\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define hyperparameters\n",
    "in_channels = 1\n",
    "im_shape = (9,9)\n",
    "n_filters = 8\n",
    "kernel_size = (3,3)\n",
    "\n",
    "# create single input ConvDipNet \n",
    "convnet: nn.Module  = ConvDipNet(in_channels, im_shape, n_filters, kernel_size)\n",
    "\n",
    "\n",
    "# print model summary\n",
    "summary(convnet, input_size=(32, 1, im_shape[0], im_shape[1])) # (batch_size, n_timesteps, in_channels, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a55af6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvDipNet(\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (hidden_layer): Linear(in_features=648, out_features=512, bias=True)\n",
       "  (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (output_layer): Linear(in_features=512, out_features=5124, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = \"/mnt/data/convdip/model/convdip_run6\"\n",
    "model_weight_path = os.path.join(model_dir, \"convdip_40.pt\")\n",
    "convnet.load_state_dict(torch.load(model_weight_path, weights_only=True))\n",
    "convnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "728aa07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = \"/mnt/data/convdip/model/\"\n",
    "loss_save_path = \"/mnt/data/convdip/model/convdip_loss.npy\"\n",
    "data_path = \"/mnt/data/convdip/training_data/\"\n",
    "eeg_data_path = os.path.join(data_path, \"eeg_data\")\n",
    "interp_data_path = os.path.join(data_path, \"interp_data\")\n",
    "source_data_path = os.path.join(data_path, \"source_data\")\n",
    "info_path = os.path.join(data_path, \"info.fif\")\n",
    "\n",
    "dataset = DipoleDataset(eeg_data_path, interp_data_path, source_data_path, info_path, im_shape=im_shape)\n",
    "test_size = 0.15\n",
    "val_size = 0.15\n",
    "\n",
    "test_amount, val_amount = int(dataset.__len__() * test_size), int(dataset.__len__() * val_size)\n",
    "\n",
    "# this function will automatically randomly split your dataset but you could also implement the split yourself\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(0) # this is the seed we use to split the data the same way each time\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [\n",
    "            (dataset.__len__() - (test_amount + val_amount)), \n",
    "            test_amount, \n",
    "            val_amount\n",
    "], generator=gen)\n",
    "\n",
    "B = 512  # batch size\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "            train_set,\n",
    "            batch_size=B,\n",
    "            shuffle=False,\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "            val_set,\n",
    "            batch_size=B,\n",
    "            shuffle=False,\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "            test_set,\n",
    "            batch_size=B,\n",
    "            shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e268634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24175\n",
      "torch.Size([1, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "dipole_pos = np.load(os.path.join(data_path, \"dipole_pos.npy\"))\n",
    "\n",
    "idx, sample, target = val_dataloader.dataset[0]\n",
    "print(idx)\n",
    "print(sample.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0330d0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  80 | elapsed:    5.9s remaining:   20.2s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  80 | elapsed:    6.0s remaining:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  80 | elapsed:    6.0s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of  80 | elapsed:    6.0s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  80 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  80 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  80 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of  80 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 80 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  80 | elapsed:    1.4s remaining:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  80 | elapsed:    1.7s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  80 | elapsed:    1.9s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of  80 | elapsed:    2.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "# create forward model\n",
    "fs = 100\n",
    "info = get_info(sfreq=fs)\n",
    "fwd = create_forward_model(sampling='ico4', info=info)\n",
    "leadfield = fwd['sol']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241a83e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample:   5%|▍         | 25/512 [01:53<36:59,  4.56s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m auc_close, auc_far \u001b[38;5;241m=\u001b[39m eval_auc(target_sample, output_sample, dipole_pos)\n\u001b[1;32m     26\u001b[0m sample_auc \u001b[38;5;241m=\u001b[39m (auc_close \u001b[38;5;241m+\u001b[39m auc_far)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 28\u001b[0m mle \u001b[38;5;241m=\u001b[39m \u001b[43meval_mean_localization_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdipole_pos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m mse \u001b[38;5;241m=\u001b[39m eval_mse(target_sample, output_sample)\n\u001b[1;32m     30\u001b[0m nmse \u001b[38;5;241m=\u001b[39m eval_nmse(target_sample, output_sample)\n",
      "File \u001b[0;32m~/convdip/esinet_MAE298/CNN_LSTM/../esinet/evaluate/evaluate.py:130\u001b[0m, in \u001b[0;36meval_mean_localization_error\u001b[0;34m(y_true, y_est, pos, k_neighbors, min_dist, threshold, ghost_thresh, argsorted_distance_matrix)\u001b[0m\n\u001b[1;32m    122\u001b[0m y_est \u001b[38;5;241m=\u001b[39m deepcopy(y_est)\n\u001b[1;32m    125\u001b[0m maxima_true \u001b[38;5;241m=\u001b[39m get_maxima_pos(\n\u001b[1;32m    126\u001b[0m     get_maxima_mask(y_true, pos, k_neighbors\u001b[38;5;241m=\u001b[39mk_neighbors, \n\u001b[1;32m    127\u001b[0m     threshold\u001b[38;5;241m=\u001b[39mthreshold, min_dist\u001b[38;5;241m=\u001b[39mmin_dist, \n\u001b[1;32m    128\u001b[0m     argsorted_distance_matrix\u001b[38;5;241m=\u001b[39margsorted_distance_matrix), pos)\n\u001b[1;32m    129\u001b[0m maxima_est \u001b[38;5;241m=\u001b[39m get_maxima_pos(\n\u001b[0;32m--> 130\u001b[0m     \u001b[43mget_maxima_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_est\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43margsorted_distance_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margsorted_distance_matrix\u001b[49m\u001b[43m)\u001b[49m, pos)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Distance matrix between every true and estimated maximum\u001b[39;00m\n\u001b[1;32m    135\u001b[0m distance_matrix \u001b[38;5;241m=\u001b[39m cdist(maxima_true, maxima_est)\n",
      "File \u001b[0;32m~/convdip/esinet_MAE298/CNN_LSTM/../esinet/evaluate/evaluate.py:27\u001b[0m, in \u001b[0;36mget_maxima_mask\u001b[0;34m(y, pos, k_neighbors, threshold, min_dist, argsorted_distance_matrix)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m''' Returns the mask containing the source maxima (binary).\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    be of significance. 0.1 -> 10% of the absolute maximum\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m argsorted_distance_matrix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m     argsorted_distance_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[43mcdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     30\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(y)\n\u001b[1;32m     31\u001b[0m threshold \u001b[38;5;241m=\u001b[39m threshold\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mmax(y)\n",
      "File \u001b[0;32m~/.pyenv/versions/esienv/lib/python3.12/site-packages/scipy/spatial/distance.py:2980\u001b[0m, in \u001b[0;36mcdist\u001b[0;34m(XA, XB, metric, out, **kwargs)\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2979\u001b[0m     cdist_fn \u001b[38;5;241m=\u001b[39m metric_info\u001b[38;5;241m.\u001b[39mcdist_func\n\u001b[0;32m-> 2980\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcdist_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mstr\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   2982\u001b[0m     metric_info \u001b[38;5;241m=\u001b[39m _TEST_METRICS\u001b[38;5;241m.\u001b[39mget(mstr, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "metric_save_path = os.path.join(model_dir, \"evaluation_metrics.json\")\n",
    "convnet.to(device)\n",
    "with torch.no_grad():\n",
    "    metrics_per_sample = {}\n",
    "    i=0\n",
    "    for idxs, batch, target in test_dataloader:\n",
    "        i+=1\n",
    "        print(i)\n",
    "        batch = batch.to(device, dtype=torch.float)\n",
    "        output = convnet(batch)\n",
    "        output = output.cpu()\n",
    "\n",
    "        for idx in tqdm(range(output.shape[0]), position=0, desc=\"sample\"):\n",
    "            data_idx = int(idxs[idx])\n",
    "            target_sample = np.array(target[idx])\n",
    "            output_sample = np.array(output[idx])\n",
    "            \n",
    "            eeg = np.load(os.path.join(data_path, f\"eeg_data/sample_{data_idx}.npy\"))\n",
    "            max_idx = np.unravel_index(np.argmax(eeg), eeg.shape)[1] # this is the timestep with the maximum eeg value, this will be used to train\n",
    "            output_sample = solve_p(output_sample, eeg[:,max_idx], leadfield)\n",
    "\n",
    "            \n",
    "            auc_close, auc_far = eval_auc(target_sample, output_sample, dipole_pos)\n",
    "            sample_auc = (auc_close + auc_far)/2\n",
    "            \n",
    "            mle = eval_mean_localization_error(target_sample, output_sample, dipole_pos)\n",
    "            mse = eval_mse(target_sample, output_sample)\n",
    "            nmse = eval_nmse(target_sample, output_sample)\n",
    "            metrics_per_sample[data_idx] = [auc_close, auc_far, mle, mse, nmse]\n",
    "            \n",
    "        \n",
    "       # with open(metric_save_path, \"w\") as json_file:\n",
    "            #json.dump(metrics_per_sample, json_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5abb2f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'9771': [0.4145663988657845, 0.29337429111531194, 36.312774929301, 0.009217227703145066, 0.13296913452703557], '4374': [0.22827919333413837, 0.08673348629392585, 35.02693422038831, 0.01775956286581762, 0.21168121131165538], '54679': [0.32557755102040814, 0.11291224489795919, nan, 0.014980096009553266, 0.14347386502750029]}\n"
     ]
    }
   ],
   "source": [
    "with open(metric_save_path, 'r') as json_file:\n",
    "    metrics = json.load(json_file)\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
