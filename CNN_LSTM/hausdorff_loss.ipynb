{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e8da3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 09:29:40.619915: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-27 09:29:40.680820: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-27 09:29:41.614799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from convnet import ConvDipNet\n",
    "from timeDistributed import TimeDistributed\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys; sys.path.insert(0, '../')\n",
    "from esinet.forward import create_forward_model, get_info\n",
    "from esinet import Simulation\n",
    "from copy import deepcopy\n",
    "from CNN_LSTM.util import *\n",
    "from dipoleDataset import DipoleDataset\n",
    "import os\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f5f37d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [[-36.25040817260742, -28.20974349975586, 9.22...\n",
      "0    [[44.33734130859375, -49.42319107055664, 20.72...\n",
      "0    [[54.335540771484375, -52.5910530090332, -17.9...\n",
      "0    [[-29.0865421295166, -93.31341552734375, -14.0...\n",
      "0    [[-34.94701385498047, -10.915384292602539, 57....\n",
      "                           ...                        \n",
      "0    [[-30.389795303344727, -58.96854782104492, -7....\n",
      "0    [[-48.558677673339844, -28.22390365600586, 19....\n",
      "0    [[9.353612899780273, -43.6870231628418, 31.143...\n",
      "0    [[37.58522033691406, -33.92412185668945, 63.67...\n",
      "0    [[-20.511646270751953, 29.38741111755371, 48.1...\n",
      "Name: positions, Length: 100000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "save_dir = \"/mnt/data/convdip/training_data\"\n",
    "sim_info = pd.read_pickle(os.path.join(save_dir, 'simulation_info.pkl'))\n",
    "pos = np.load(os.path.join(save_dir, \"dipole_pos.npy\"))\n",
    "\n",
    "positions_per_trial = sim_info['positions']\n",
    "del sim_info\n",
    "print(positions_per_trial)\n",
    "\n",
    "target = positions_per_trial.iloc[1]\n",
    "match = (pos == target)\n",
    "row_eq = match.all(axis=1)\n",
    "\n",
    "pos[np.where(row_eq)[0]]\n",
    "pos = torch.tensor(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57148c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_euclidean_distance(points):\n",
    "    \"\"\"\n",
    "    Find the maximum Euclidean distance between any two points.\n",
    "    \n",
    "    Args:\n",
    "        points: numpy array of shape (n, 3) containing 3D coordinates\n",
    "    \n",
    "    Returns:\n",
    "        max_distance: float, the maximum distance\n",
    "        indices: tuple (i, j), indices of the two points with max distance\n",
    "    \"\"\"\n",
    "    # Compute all pairwise squared distances using broadcasting\n",
    "    # diff shape: (n, n, 3)\n",
    "    diff = points[:, np.newaxis, :] - points[np.newaxis, :, :]\n",
    "    \n",
    "    # Compute squared distances, shape: (n, n)\n",
    "    sq_distances = np.sum(diff**2, axis=2)\n",
    "    \n",
    "    # Find the maximum\n",
    "    max_sq_dist = np.max(sq_distances)\n",
    "    max_distance = np.sqrt(max_sq_dist)\n",
    "    \n",
    "    # Get indices of maximum distance\n",
    "    i, j = np.unravel_index(np.argmax(sq_distances), sq_distances.shape)\n",
    "    \n",
    "    return max_distance, (i, j)\n",
    "\n",
    "def cdist(x, y):\n",
    "    '''\n",
    "    Input: x is a Nxd Tensor\n",
    "        y is a Mxd Tensor\n",
    "    Output: dist is a NxM matrix where dist[i,j] is the norm\n",
    "        between x[i,:] and y[j,:]\n",
    "    i.e. dist[i,j] = ||x[i,:]-y[j,:]||\n",
    "    '''\n",
    "    differences = x.unsqueeze(1) - y.unsqueeze(0)\n",
    "    distances = torch.sum(differences**2, -1).sqrt()\n",
    "    return distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8073cec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169.42452954118374"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_d, _ = max_euclidean_distance(pos)\n",
    "max_d\n",
    "\n",
    "distances = cdist(pos, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8745a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/mnt/data/convdip/training_data/\"\n",
    "eeg_data_dir = os.path.join(data_dir, \"eeg_data\")\n",
    "interp_data_dir = os.path.join(data_dir, \"interpolated_eeg_data_for_lstm\")\n",
    "source_data_dir = os.path.join(data_dir, \"source_data\")\n",
    "info_path = os.path.join(data_dir, \"info.fif\")\n",
    "dataset = DipoleDataset(eeg_data_dir, interp_data_dir, source_data_dir, info_path, get_whole_trial=False)\n",
    "test_size = 0.15\n",
    "val_size = 0.15\n",
    "\n",
    "test_amount, val_amount = int(dataset.__len__() * test_size), int(dataset.__len__() * val_size)\n",
    "\n",
    "# this function will automatically randomly split your dataset but you could also implement the split yourself\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(0)\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [\n",
    "            (dataset.__len__() - (test_amount + val_amount)), \n",
    "            test_amount, \n",
    "            val_amount], \n",
    "            generator=gen)\n",
    "\n",
    "B = 512  # batch size\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "            train_set,\n",
    "            batch_size=B,\n",
    "            shuffle=True,\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "            val_set,\n",
    "            batch_size=B,\n",
    "            shuffle=True,\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "            test_set,\n",
    "            batch_size=B,\n",
    "            shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba7f76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/137 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., dtype=torch.float64)\n",
      "tensor(1., dtype=torch.float64)\n",
      "tensor(29.2278, dtype=torch.float64)\n",
      "tensor(56.9732, dtype=torch.float64)\n",
      "38425\n",
      "torch.Size([3, 3])\n",
      "tensor(29.2278, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from WHD import WHD\n",
    "\n",
    "whd = WHD(pos, positions_per_trial)\n",
    "\n",
    "eps = 1e-6\n",
    "alpha = 4\n",
    "\n",
    "def WHD(prob_map, gt_points, pos):\n",
    "    n_est_pts = prob_map.sum()\n",
    "    d_matrix = cdist(pos, gt_points)\n",
    "    p_replicated = prob_map.view(-1,1).repeat(1, gt_points.shape[0])\n",
    "    term_1 = (1 / (n_est_pts + eps)) * torch.sum(prob_map*torch.min(d_matrix, 1)[0])\n",
    "    d_div_p = torch.min((d_matrix + eps) / (p_replicated**alpha + eps / max_d), 0)[0]\n",
    "    d_div_p = torch.clamp(d_div_p, 0, max_d)\n",
    "    term_2 = torch.mean(d_div_p, 0)\n",
    "    return term_1 + term_2\n",
    "\n",
    "\n",
    "device = \"cpu\" #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "for j, data in enumerate(tqdm(train_dataloader)):\n",
    "    idx, sample, target = data\n",
    "    #sample, target = sample.to(device, dtype=torch.float), target.to(device, dtype=torch.float)\n",
    "    target_locations = positions_per_trial.iloc[idx]\n",
    "\n",
    "    for b in range(B):\n",
    "        prob_map = target[b, :]\n",
    "        prob_map = torch.relu(prob_map)\n",
    "\n",
    "        whd_class = whd.WHD(prob_map, int(idx[b]))\n",
    "        print(whd_class)\n",
    "        break\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3614bd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/137 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/137 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.5265e-14, dtype=torch.float64)\n",
      "tensor(214.0000, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for j, data in enumerate(tqdm(train_dataloader)):\n",
    "    idx, sample, target = data\n",
    "    for b in range(B):\n",
    "        output = target[b,:]\n",
    "        specific_target = target[b,:]\n",
    "        specific_target2 = target[b+2, :]\n",
    "        loss2 = -torch.matmul(output, specific_target2.T) + torch.log(torch.sum(torch.exp(torch.matmul(output.T, target.T)))) \n",
    "        loss = -torch.matmul(output, specific_target.T) + torch.log(torch.sum(torch.exp(torch.matmul(output.T, target.T))))\n",
    "        print(loss)\n",
    "        print(loss2)\n",
    "        break\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
