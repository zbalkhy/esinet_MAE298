{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d22f2acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from convnet import ConvDipNet\n",
    "from timeDistributed import TimeDistributed, TimeDistributedLinear\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys; sys.path.insert(0, '../')\n",
    "from esinet.forward import create_forward_model, get_info\n",
    "from esinet import Simulation\n",
    "from copy import deepcopy\n",
    "from CNN_LSTM.util import *\n",
    "from dipoleDataset import DipoleDataset\n",
    "import os\n",
    "import mne\n",
    "from cnn_lstm import CNNLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89a021b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_MSE_loss(outputs, targets):\n",
    "    weights = torch.softmax(targets, dim=-1) # sum along the dipole dimension\n",
    "    error = (targets-outputs)**2\n",
    "    return torch.mean(weights*error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9433de9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNNLSTM                                  [32, 100, 5124]           --\n",
       "├─TimeDistributed: 1-1                   [32, 100, 5124]           --\n",
       "│    └─ConvDipNet: 2-1                   [3200, 5124]              --\n",
       "│    │    └─Conv2d: 3-1                  [3200, 8, 9, 9]           80\n",
       "│    │    └─BatchNorm2d: 3-2             [3200, 8, 9, 9]           16\n",
       "│    │    └─Linear: 3-3                  [3200, 512]               332,288\n",
       "│    │    └─BatchNorm1d: 3-4             [3200, 512]               1,024\n",
       "│    │    └─Linear: 3-5                  [3200, 5124]              2,628,612\n",
       "├─TimeDistributedLinear: 1-2             [32, 100, 512]            --\n",
       "│    └─Linear: 2-2                       [3200, 512]               2,624,000\n",
       "├─LSTM: 1-3                              [32, 100, 1024]           6,299,648\n",
       "├─LayerNorm: 1-4                         [32, 100, 1024]           2,048\n",
       "├─TimeDistributedLinear: 1-5             [32, 100, 5124]           --\n",
       "│    └─Linear: 2-3                       [3200, 5124]              5,252,100\n",
       "==========================================================================================\n",
       "Total params: 17,139,816\n",
       "Trainable params: 17,139,816\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 54.86\n",
       "==========================================================================================\n",
       "Input size (MB): 1.04\n",
       "Forward/backward pass size (MB): 387.28\n",
       "Params size (MB): 68.56\n",
       "Estimated Total Size (MB): 456.87\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define hyperparameters\n",
    "in_channels = 1\n",
    "im_shape = (9,9)\n",
    "n_filters = 8\n",
    "kernel_size = (3,3)\n",
    "\n",
    "# create single input ConvDipNet\n",
    "cnnlstm = CNNLSTM(in_channels, im_shape, n_filters, kernel_size)\n",
    "\n",
    "# print model summary\n",
    "summary(cnnlstm, input_size=(32, 100, 1, im_shape[0], im_shape[1])) # (batch_size, n_timesteps, in_channels, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a3b50bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/mnt/data/convdip/training_data/\"\n",
    "eeg_data_dir = os.path.join(data_dir, \"eeg_data\")\n",
    "interp_data_dir = os.path.join(data_dir, \"interpolated_eeg_data_for_lstm\")\n",
    "source_data_dir = os.path.join(data_dir, \"source_data\")\n",
    "info_path = os.path.join(data_dir, \"info.fif\")\n",
    "dataset = DipoleDataset(eeg_data_dir, interp_data_dir, source_data_dir, info_path, im_shape=im_shape, get_whole_trial=True)\n",
    "test_size = 0.15\n",
    "val_size = 0.15\n",
    "\n",
    "test_amount, val_amount = int(dataset.__len__() * test_size), int(dataset.__len__() * val_size)\n",
    "\n",
    "# this function will automatically randomly split your dataset but you could also implement the split yourself\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(0)\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [\n",
    "            (dataset.__len__() - (test_amount + val_amount)), \n",
    "            test_amount, \n",
    "            val_amount], \n",
    "            generator=gen)\n",
    "\n",
    "B = 512  # batch size\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "            train_set,\n",
    "            batch_size=B,\n",
    "            shuffle=True,\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "            val_set,\n",
    "            batch_size=B,\n",
    "            shuffle=True,\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "            test_set,\n",
    "            batch_size=B,\n",
    "            shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b18a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 54/137 [02:57<04:35,  3.32s/it]"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "betas=(0.9, 0.999)\n",
    "eps = 1e-8\n",
    "optimizer = optim.Adam(cnnlstm.parameters(), lr=lr, \n",
    "                    betas=betas, eps=eps)\n",
    "\n",
    "model_save_path = \"/mnt/data/convdip/model/\"\n",
    "loss_save_path = \"/mnt/data/convdip/model/cnnlstm_loss.npy\"\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "cnnlstm.to(device)\n",
    "\n",
    "for epoch in range(500):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for j, data in enumerate(tqdm(train_dataloader)):\n",
    "        sample, target = data\n",
    "        sample, target = sample.to(device, dtype=torch.float), target.to(device, dtype=torch.float)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = cnnlstm(sample)\n",
    "        loss = weighted_MSE_loss(outputs, target)#criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    print(f'[{epoch + 1}] loss: {running_loss:.8e}')\n",
    "    loss_values.append(running_loss)\n",
    "    if epoch % 50 == 0:\n",
    "        np.save(loss_save_path, np.array(loss_values))\n",
    "        torch.save(cnnlstm.state_dict(), os.path.join(model_save_path,\"cnnlstm_{}.pt\".format(epoch)))\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "np.save(loss_save_path, np.array(loss_values))\n",
    "torch.save(cnnlstm.state_dict(), os.path.join(model_save_path,\"cnnlstm_{}.pt\".format(epoch)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
